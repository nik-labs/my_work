
---
title: "Re: Referencing the MovieLens Dataset to Predict Movie Ratings"
author: "Nik S."
date: "Jan 2, 2020"
output:
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
    highlight: pygments
    keep_tex: true
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center', cache=FALSE, cache.lazy = FALSE)
```

```{r, include=FALSE, echo=FALSE}
# Package installs

if(!require(tidyverse)) install.packages("tidyverse") 
if(!require(kableExtra)) install.packages("kableExtra")
if(!require(tidyr)) install.packages("tidyr")
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(forcats)) install.packages("forcats")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(stringr)) install.packages("stringr")
```

```{r, include=FALSE, echo=FALSE}
# Loading libraries as needed

library(dplyr)
library(tidyverse)
library(kableExtra)
library(tidyr)
library(forcats)
library(ggplot2)
library(stringr)
```


```{r, include=FALSE, echo=FALSE}
###############################################################
#Project MovieLens (HarvardX: PH125.9x Data Science: Capstone) 
#Create edx set, validation set
#GitHub repository is here: https://github.com/nik-labs/MovieLens  
###############################################################

## Note: this process could take a couple of minutes because it is loading packages such astidyverse and caret

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)

colnames(movies) <- c("movieId", "title", "genres")

movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")


# Validation set will be 10% of MovieLens data
# Using R 3.6.2 version

set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]


# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>%
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")


# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)
rm(dl, ratings, movies, test_index, temp, movielens, removed)
save(edx, validation, file = datafile)

} else {
  load(datafile)
}

```
# Introduction

Background:  The Netflix data is not publicly available, but the GroupLens research lab generated their own database with over 20 million ratings for over 27,000 movies by more than 138,000 users. 
 
Project Objective: The focus is to create a movie recommendation system which will reduce the Root Mean Squared Error (RMSE) to less than or equal to 0.8649. To clarify, RMSE measures accuracy by stating differences between prediction values and observed values.  This initiative will leverage a small subset of the entire data population use in the Netflix Prize competition; specifically, the validation set will be 10% of MovieLens data due to the sheer volume of the database population. There was a skeleton framework of code provided to generate the intended datasets. The developed algorithm leverages the edx set. Additionally, the final test of the algorithm predicts movie ratings in the validation set as if they were unknown. RMSE will be used to evaluate how close the predictions are to the true values in the validation set. 

The RMSE function that will be used in this project is:
RMSE <- function(true_ratings = NULL, predicted_ratings = NULL) {
    sqrt(mean((true_ratings - predicted_ratings)^2))
}
```  

# Methods and Analysis

Upon review of the edx subset, there are six columns that denote the following – userId, moveId, timestamp, title, and genres. Each entry illustrates a under rating for a specific movie (e.g., row#1 illustrates user rating for the movie Boomerang from 1992). 
 
Summarize Data:Total unique movies and users

```{r head, echo = FALSE}
head(edx) %>%
  print.data.frame()
summary(edx)
```

Movies, Users and Genres in Database
```{r head, echo = FALSE}
edx %>%
summarize(n_users = n_distinct(userId), 
            n_movies = n_distinct(movieId),
	    n_genres = n_distinct(genres))
mean(edx$rating)
```

Histogram: Ratings distribution in blue color font
```{r rating_distribution, echo = FALSE}
edx %>%
  ggplot(aes(rating)) +
  geom_histogram(binwidth = 0.25, color = "blue") +
  scale_x_discrete(limits = c(seq(0.5,5,0.5))) +
  scale_y_continuous(breaks = c(seq(0, 3000000, 500000))) +
  ggtitle("Rating Distribution")

```
The number of ratings per movie varies and some so much so that movies which have received limited number of ratings may not be ones that can be relied upon. Specifically, movies which received a rating a piece tally up to 125 movies and should be candidates that should be carved out of reliable data. To account for such anomalies in the observed dataset below, regularization is employed to reduce fitting closely to skewed functions. Moreover, having the error function incorporate a penalty component allows for discounting atypical data. 

Plot number of ratings per movie in blue color font
```{r number_of_ratings_per_movie, echo = TRUE, fig.height=4, fig.width=5}


edx %>%
  count(movieId) %>%
  ggplot(aes(n)) +
  geom_histogram(bins = 30, color = "blue") +
  scale_x_log10() +
  xlab("Number of Ratings") +
  ylab("Number of Movies") +
  ggtitle("Number of Ratings per Movie")

```

It does not seem warranted to include this set of titles to base predictions, as we see that the list of these 20 movie titles only received one user rating each respectively. 

Movies rated only once

```{r obscure_movies, echo = TRUE, fig.height=4, fig.width=5}
edx %>%
  group_by(movieId) %>%
  summarize(count = n()) %>%
  filter(count == 1) %>%
  left_join(edx, by = "movieId") %>%
  group_by(title) %>%
  summarize(rating = rating, n_rating = count) %>%
  slice(1:20) %>%
  knitr::kable()
```

It can be observed that the vast number of users have rated movies within 35 and 100 movies. Since there is a wide range, a user penalty component will need to be factored into the prediction model. 
 
Plot Ratings Users - Number of Ratings in blue color font

```{r number_ratings_given_by_users, echo = TRUE, fig.height=4, fig.width=5}
edx %>%
  count(userId) %>%
  ggplot(aes(n)) +
  geom_histogram(bins = 30, color = "black") +
  scale_x_log10() +
  xlab("Number of Ratings") + 
  ylab("Number of Users") +
  ggtitle("User provided Number of Ratings")
```


Plot Ratings Users - Mean

```{r Mean_movie_ratings_given_by_users, echo = TRUE, fig.height=4, fig.width=5}
edx %>%
  group_by(userId) %>%
  filter(n() >= 100) %>%
  summarize(b_u = mean(rating)) %>%
  ggplot(aes(b_u)) +
  geom_histogram(bins = 30, color = "black") +
  xlab("Mean Rating") +
  ylab("Number of Users") +
  ggtitle("User provided mean movie ratings") +
  scale_x_discrete(limits = c(seq(0.5,5,0.5))) +
  theme_light()

```



### Data Analysis - Average movie rating model

We will first look at the average movie rating model (mean rating) which predicts the rating for all movies across the dataset. The expected rating of the dataset is between 3 and 4. This simple recommendations system works under the criteria that the same rating for all movies is predicted agnostic to the user. 
 
 
A model based approach assumed the same rating for all movies with differences accounted by random variation: $$ Y_{u, i} = \mu + \epsilon_{u, i} $$ ; where $\epsilon_{u,i}$  is independent error sample for the same distribution centered at 0 and mu the true rating for all movies.   
 
Simple Prediction based on Mean Rating

```{r, echo = TRUE}
mu <- mean(edx$rating)
mu

```

Now, if all unknown ratings with the mean rating, mu is predicted, we can calculate the naïve RMSE as follows: 
 
```{r naive_rmse, echo = TRUE} 
naive_rmse <- RMSE(validation$rating, mu)
naive_rmse
```

We will use the Naïve RMSE in Table 6 to compare our prediction effectiveness. To improve our prediction methodology. 

Validate and Save Results in date frame called rmse_ouputs

```{r rmse_results1, echo = TRUE}
rmse_ouputs <- data_frame(method = "Average movie rating model", RMSE = naive_rmse)
rmse_ouputs %>% knitr::kable()

```

REFINING THE PREDICTION MODEL: Movie Effect Movie-specific effect is approximated by  $$Y_{u, i} = \mu +b_{i}+ \epsilon_{u, i}$$; where is “b” is bias for each movie “i” that represents the average ranking for movie i 


Movie effect model: Simple model considerating movie effect b_i
Subtract the rating minus the mean for each rating the movie received
Plot number of movies with the computed b_i

```{r Number_of_movies_with_the computed_b_i, echo = TRUE, fig.height=3, fig.width=4}
movie_avgs <- edx %>%
  group_by(movieId) %>%
  summarize(b_i = mean(rating - mu))
movie_avgs %>% qplot(b_i, geom ="histogram", bins = 10, data = ., color = I("black"),
                     ylab = "Number of movies", main = "Number of movies with the computed b_i")

```


The penalty incorporated into the movie effect will now be used to improve the prediction model. 
Test and save rmse results. 

```
predicted_rating_values <- mu +  validation %>%
  left_join(movie_avgs, by='movieId') %>%
  pull(b_i)
rmse_model1 <- RMSE(predicted_rating_values, validation$rating)
rmse_ouputs <- bind_rows(rmse_ouputs,
                          data_frame(method="Movie effect model",  

rmse_ouputs %>% knitr::kable()

```

REFINING THE PREDICTION MODEL: Movie Effect & User Effect Model Now look to calculate the average user rating, mu for those users whom have rated over 100 movies with the incorporation of the penalty term. Looking below, there is apparent user provided variance across movie ratings.


Movie and user effect model:Plot penalty term user effect

```{r, echo = TRUE}
# Plot penalty term user effect #
user_avgs<- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  filter(n() >= 100) %>%
  summarize(b_u = mean(rating - mu - b_i))
user_avgs%>% qplot(b_u, geom ="histogram", bins = 30, data = ., color = I("black"))

```

There is further opportunity to refine the model to mitigate large swings in ratings whereby a user with a negative bu rates a movie with a positive bi will result in a negating effect and so will use the following formula below to predict that the user in the aforementioned example gave the movie a 3 score versus a 5. 

Calculating Average of bu by way of $$Y_{u, i} = \mu + b_{i} + b_{u} + \epsilon_{u, i}$$ ; where a and n approximation is calculated for mu and b_{i} 
 
From the below, iterative refinement in prediction models as reduced RMSE value. However, this model is still from perfect as bi estimates (either negative or positive) are likely to increase RMSE values. To enhance the approach, we will need one prediction value not confidence intervals with associated stand error for various levels of uncertainty. 


```{r user_avgs, echo = TRUE}
user_avgs <- edx %>%
left_join(movie_avgs, by='movieId') %>%
group_by(userId) %>%
summarize(b_u = mean(rating - mu - b_i))
                                                             
```



Test and save rmse results
 
```{r model_2_rmse, echo = TRUE}
predicted_rating_values <- validation%>%
left_join(movie_avgs, by='movieId') %>%
left_join(user_avgs, by='userId') %>%
mutate(pred = mu + b_i + b_u) %>%
pull(pred)
                                                             
model_2_rmse <- RMSE(predicted_rating_values, validation$rating)
rmse_ouputs <- bind_rows(rmse_ouputs,
data_frame(method="Movie and user effect model",  
RMSE = model_2_rmse))
rmse_ouputs %>% knitr::kable()

```                                                    


REFINING THE PREDICTION MODEL: Regularized movie effect and user effect model 
 
From the below, using regularization to penalize the fact that some users only rated a small set of movies as well as the fact that movies may receive few ratings. 
 

Regularization ovie and user effect model: Predict via regularisation, movie and user effect model

```{r lambdas, echo = TRUE}
lambdas <- seq(0, 10, 0.25)

rmses <- sapply(lambdas, function(l){
                                                               
mu <- mean(edx$rating)
 
b_i <- edx %>% 
group_by(movieId) %>%
summarize(b_i = sum(rating - mu)/(n()+l))
                                                               
b_u <- edx %>% 
left_join(b_i, by="movieId") %>%
group_by(userId) %>%
summarize(b_u = sum(rating - b_i - mu)/(n()+l))
                                                               
predicted_rating_values <- 
validation %>% 
left_join(b_i, by = "movieId") %>%
left_join(b_u, by = "userId") %>%
mutate(pred = mu + b_i + b_u) %>%
pull(pred)
                                                               
return(RMSE(predicted_rating_values, validation$rating))
})

```

                                                             
                                                             
Plot RMSE against Lambdas to find optimal lambda                                             
```{r plot_lambdas, echo = TRUE}              
qplot(lambdas, rmses)  

```
                                                          
                                                             
The calculated optimal lambda value is 5.25 as denoted below.                                                            

```{r min_lambda, echo = TRUE}
lambda <- lambdas[which.min(rmses)]
lambda

```      

                                                      
Test and save results                                                             

```{r rmse_results2, echo = TRUE}
rmse_ouputs <- bind_rows(rmse_ouputs,
data_frame(method="Regularized movie and user effect model",  
RMSE = min(rmses)))

rmse_ouputs %>% knitr::kable()
```
\pagebreak


# Final Results - MovieLens Dataset

Illustrated below in Table 13, are all of the RMSE values from the iterative prediction models that were utilized throughout this report for comparison: 
                                                           
RMSE Results - Providing the appropriate score given the reported RMSE. It can be concluded that the lowest RMSE value obtained is 0.8648170.                       

```{r rmse_results3, echo = FALSE}                                                           rmse_ouputs %>% knitr::kable()

```


# Conclusion

It was observed that throughout this project, there was a test and learn approach to iteratively use various predictive models to seek the most accurate method, which in this case is the regularization model; this incorporated the movie and user effect. The objective to achieve a Root Mean Squared Error (RMSE) less than 0.8649 was successfully attained, specifically a RMSE value of 0.8648170 was concluded.

\pagebreak
 
